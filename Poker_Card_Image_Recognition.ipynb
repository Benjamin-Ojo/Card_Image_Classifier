{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaGVRa7p9K1daJYDQCOqwc"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project: Card Image Classification**\n",
        "---"
      ],
      "metadata": {
        "id": "oIUoVj-zM97u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introduction:**\n",
        "\n",
        "Welcome to an exciting project where we will be exploring the fascinating world of image recognition! Our project focuses on the task of classifying a set of poker cards into 53 different categories based on their type.\n",
        "\n",
        "Using a Convolutional Neural Network (CNN) model, we will train our model to accurately classify images of poker cards into any of the 53 categories. Our dataset, which was obtained from a popular data science community, Kaggle, contains a total of 8154 images of poker cards, divided into 7624 train, 265 test, and 265 validation sets. Each image is a 224 x 224 3-dimensional jpg format.\n",
        "\n",
        "The dataset we used for this project can be found on the Kaggle website at the following link: [Cards Image Dataset-Classification](https://www.kaggle.com/datasets/gpiosenka/cards-image-datasetclassification). This project will not only teach us how to build a powerful image recognition model using a CNN model, but it will also give us a deeper understanding of the complexities involved in training a machine learning algorithm to recognize images. So, buckle up, and let's dive into this thrilling project together!"
      ],
      "metadata": {
        "id": "V5TvsdU9NP99"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prject Break Down: \n",
        "The project would be broken down in the following:\n",
        "Certainly! Here's a breakdown of what this image recognition project will entail:\n",
        "\n",
        "1. **Data Wrangling:** We will download the poker card image dataset from Kaggle and examine the images to gain insights into the data.\n",
        "\n",
        "2. **Data Preprocessing:** We will preprocess the images by resizing them to a standard size and converting them into an array format suitable for feeding into our CNN model.\n",
        "\n",
        "3. **Data Augmentation:** We will use data augmentation techniques such as image rotation, flipping, and zooming to increase the size of our dataset and improve the robustness of our model.\n",
        "\n",
        "4. **Model Building:** We will build a CNN model using Keras with TensorFlow backend, and train the model using our preprocessed dataset. We will experiment with different architectures, hyperparameters, and optimization algorithms to achieve optimal performance.\n",
        "\n",
        "5. **Model Evaluation:** We will evaluate the performance of our model using various metrics such as accuracy, precision, recall, and F1 score, and visualize the results using confusion matrix and classification report.\n",
        "\n",
        "6. **Model Deployment:** We will deploy our trained model to make predictions on new, unseen poker card images, and visualize the predictions.\n",
        "\n"
      ],
      "metadata": {
        "id": "HYCSITnTRFdD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Wrangling:**"
      ],
      "metadata": {
        "id": "07Rrcv_xXN5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Collection:\n",
        "\n",
        "We will be downloading our dataset form kaggle and extracting the data from the zip foulder it enclosed in using zipfile package."
      ],
      "metadata": {
        "id": "CsBoRvq-XgSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset folder. \n",
        "! mkdir 1.Dataset."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FEgSKNFNODX",
        "outputId": "80de2f5b-612e-47db-aac4-d9463db01592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘1.Dataset.’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Kaggle Data Import\n",
        "\n",
        "We will be downloading our dataset directly from kaggle to our colab notebook using the kaggle api. "
      ],
      "metadata": {
        "id": "hqGuSEmDV_Tm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install kaggle api with Pip. \n",
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "fCUpSOGwlqhG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5790ab2-09e7-4ab4-b271-61c94d6eed50"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uploading Kaggle api token key.\n",
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "yh-iojUmXKQW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}